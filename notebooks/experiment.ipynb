{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelkoh/projects/ragas_evaluation/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "from application.llm_service import LLMService\n",
    "from infrastructure.text_embedding_pipeline import VectorStore\n",
    "from application.ragas_evaluator import RAGASEvaluator\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "file_path = \"../data/example.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelkoh/projects/ragas_evaluation/notebooks/../src/infrastructure/text_embedding_pipeline.py:32: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  self.embedding_model = OpenAIEmbeddings(api_key=api_key)\n"
     ]
    }
   ],
   "source": [
    "faiss_vector_store = VectorStore(api_key)\n",
    "open_ai_llm = LLMService(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_answer_pairs = {\n",
    "    \"What is the product?\": \"GROW\",\n",
    "}\n",
    "ragas_evaluator = RAGASEvaluator(\n",
    "    vector_store=faiss_vector_store,\n",
    "    llm_service=open_ai_llm,\n",
    "    query_answer_pairs=query_answer_pairs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 2 relevant documents for query: What is the product?\n",
      "Error generating response: 'AIMessage' object has no attribute 'choices'\n"
     ]
    }
   ],
   "source": [
    "ragas_evaluator.create_evaluation_dataset(top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 3/3 [00:05<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.0000, 'faithfulness': 0.0000, 'factual_correctness(mode=f1)': 0.0000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_evaluator.evaluate(\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleTurnSample(user_input='What is the product?', retrieved_contexts=['2        None  None  Start a live chat at ourwebsite https://singli...  None\\n3        None  None                               service@singlife.com  None\\n4        None  None                              hotline: +65 69111111  None', '0     1                                                  2     3\\n0  N eedhelp?  If y  ouneedhelp andanswersto yourpolicy,getin touch...      \\n1        None  None                           https://faq.singlife.com  None'], reference_contexts=None, response='An error occurred while generating the response.', multi_responses=None, reference='GROW', rubrics=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_evaluator.evaluation_dataset.samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = faiss_vector_store.retrieve_relevant_text(\n",
    "    \"I need to withdraw money from my account, how can I do that?\", top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FaissVectorStore in module infrastructure.text_embedding_pipeline object:\n",
      "\n",
      "class FaissVectorStore(builtins.object)\n",
      " |  FaissVectorStore(embedding_model: infrastructure.text_embedding_pipeline.EmbeddingModel, index_path: str = '../ragas_evaluation/faiss_index') -> None\n",
      " |\n",
      " |  Handles FAISS-based vector storage and retrieval.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, embedding_model: infrastructure.text_embedding_pipeline.EmbeddingModel, index_path: str = '../ragas_evaluation/faiss_index') -> None\n",
      " |      Initialize FAISS store with an embedding model and index path.\n",
      " |\n",
      " |  load_index(self) -> None\n",
      " |      Loads the FAISS index from disk.\n",
      " |\n",
      " |  query_text(self, query: str, top_k: int) -> List[str]\n",
      " |      Retrieves the most relevant chunks from FAISS.\n",
      " |\n",
      " |  store_text_chunks(self, chunks: List[str]) -> None\n",
      " |      Stores the text chunks in FAISS after generating embeddings.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(faiss_vector_store.vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infrastructure.pdf_parser import PDFParser\n",
    "from infrastructure.text_embedding_pipeline import TextChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_doc = PDFParser(file_path)\n",
    "parsed_data = pdf_doc.parse()\n",
    "text = parsed_data.get(\"text\", \"\")\n",
    "tables = parsed_data.get(\"tables\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16939"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunker = TextChunker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
